{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from custom_models import *\n",
    "from inception_utils import *\n",
    "from image_processing import *\n",
    "from video_processing import *\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, model_flow, num_labels, classes_dictionary,  w, fnb):    \n",
    "    start = time.time()\n",
    "\n",
    "    root_path1 = 'full_videos_dataset/frames/'\n",
    "    root_path2 = 'full_videos_dataset/flow_images/'\n",
    "\n",
    "    print('\\n\\nCurrently getting predictions with weighted average ( rgb =',w[0],', flow =',w[1],' )')\n",
    "\n",
    "    conf_mat = np.zeros((num_labels,num_labels))\n",
    "    top5_correct = 0\n",
    "    vids_per_class = np.zeros(num_labels) #keep it for later stats extraction\n",
    "\n",
    "    pred_out = open('results/video_sequence_results/combo'+str(fnb)+'/video_sequence_predictions_'+str(w[0])+'_'+str(w[1])+'.txt','w')\n",
    "\n",
    "    cntr,N=0,3783\n",
    "    for line in open('data_a/ucf101_split1_testVideos.txt','r'):       \n",
    "        videoname1 = root_path1 + line.split()[0].split('/')[1]\n",
    "        videoname2 = root_path2 + line.split()[0].split('/')[1]\n",
    "        label = int(line.split()[1])\n",
    "\n",
    "        vids_per_class[label] +=1\n",
    "\n",
    "        #get mean of every column (101 of them) to find later greatest value among 101 and get predicted class\n",
    "        if(w[0]==0.0):\n",
    "            rgb_pred = np.zeros((101))\n",
    "            flow_pred = get_video_pred(videoname2,model_flow,'flow_images')\n",
    "        elif(w[1]==0.0):\n",
    "            rgb_pred = get_video_pred(videoname1,model,'frames')\n",
    "            flow_pred = np.zeros((101))\n",
    "        else:\n",
    "            rgb_pred = get_video_pred(videoname1,model,'frames')\n",
    "            flow_pred = get_video_pred(videoname2,model_flow,'flow_images')\n",
    "\n",
    "        weighted_pred = w[0]*rgb_pred + w[1]*flow_pred\n",
    "\n",
    "        conf_mat[weighted_pred.argmax(),label] += 1  \n",
    "\n",
    "        pred_out.write('{:30} was classified as : {:25}'.format(line.split()[0].split('/')[1],classes_dictionary[weighted_pred.argmax()]))#,'with max_pred={:.4f}'.format(weighted_pred.max()))\n",
    "        pred_out.write('\\n\\nTop 5 predictions\\n-----------------\\n')\n",
    "\n",
    "        ind = np.argpartition(weighted_pred, -5)[-5:]\n",
    "        for i,cnt in zip(reversed(ind[np.argsort(weighted_pred[ind])]),range(5)):\n",
    "            pred_out.write(str(cnt+1)+' '+classes_dictionary[i]+'\\n')#, weighted_pred[i])\n",
    "            if(i==label):\n",
    "                top5_correct += 1\n",
    "        pred_out.write('\\n'+'-'*73+'\\n')\n",
    "\n",
    "        cntr+=1\n",
    "        print('{:.2f}'.format(cntr/N*100), end='',flush=True)\n",
    "        print('\\r', end='')\n",
    "        del rgb_pred,flow_pred,weighted_pred\n",
    "    pred_out.close()\n",
    "\n",
    "    #######################\n",
    "    accuracy = np.trace(conf_mat) / np.sum(conf_mat)\n",
    "    print('\\tAccuracy is {:.3f}'.format(accuracy*100),'%')\n",
    "\n",
    "    top5_accuracy = top5_correct / np.sum(conf_mat)\n",
    "    print('\\tTop-5 Accuracy is {:.3f}'.format(top5_accuracy*100),'%')\n",
    "\n",
    "    #######################\n",
    "    df_cm = pd.DataFrame(conf_mat, index = [classes_dictionary[i] for i in ([i for i in range(num_labels)])],\n",
    "                                 columns = [classes_dictionary[i] for i in ([i for i in range(num_labels)])])\n",
    "    sn.set(rc={'figure.figsize':(50,50)})\n",
    "    sn.heatmap(df_cm, annot=True).figure.savefig('results/video_sequence_results/combo'+str(fnb)+'/video_sequence_conf_mat_'+str(w[0])+'_'+str(w[1])+'.png', dpi=100)\n",
    "    plt.close() \n",
    "    \n",
    "    sn.set(rc={'figure.figsize':(30,30)})    \n",
    "    sn.heatmap(df_cm, annot=False).figure.savefig('results/video_sequence_results/combo'+str(fnb)+'/video_sequence_conf_mat_no_annot_'+str(w[0])+'_'+str(w[1])+'.png', dpi=100)\n",
    "    plt.close() \n",
    "    \n",
    "    np.save('results/video_sequence_results/combo'+str(fnb)+'/conf_mat_'+str(w[0])+'_'+str(w[1])+'.npy',conf_mat)\n",
    "    \n",
    "    #######################\n",
    "    stats_out = open('results/video_sequence_results/combo'+str(fnb)+'/video_sequence_stats_'+str(w[0])+'_'+str(w[1])+'.txt','w')    \n",
    "    for i in range(num_labels):\n",
    "        stats_out.write('Classified correctly '+str(int(conf_mat[i,i]))+' of '+str(int(vids_per_class[i]))+' for class '+classes_dictionary[i]+'\\n')\n",
    "    stats_out.close()\n",
    "\n",
    "    print('\\tExecution time {:.2f}'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_combo(model, model_flow, num_labels, classes_dictionary, weights, fnb):\n",
    "    start = time.time()\n",
    "\n",
    "    get_predictions(model, model_flow, num_labels, classes_dictionary,  weights[0], fnb)    \n",
    "    get_predictions(model, model_flow, num_labels, classes_dictionary,  weights[1], fnb)\n",
    "    get_predictions(model, model_flow, num_labels, classes_dictionary,  weights[2], fnb)    \n",
    "    get_predictions(model, model_flow, num_labels, classes_dictionary,  weights[3], fnb)\n",
    "    get_predictions(model, model_flow, num_labels, classes_dictionary,  weights[4], fnb)\n",
    "    \n",
    "    print('\\n\\nExecution time {:.2f}'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_input = (seq_len,crop_height,crop_width,3)\n",
    "\n",
    "classes_dictionary = pickle.load(open('data_a/action_dictionary.p','rb'))\n",
    "\n",
    "rgb_path = 'saved_models/lstm_rgb.hdf5'\n",
    "flow_paths = ['saved_models/lstm_flow.hdf5','saved_models/lstm_flow_1024.hdf5']\n",
    "\n",
    "model = LSTMCaffeDonahueFunctional(seq_input=seq_input, num_labels=num_labels)\n",
    "model.load_weights(rgb_path)\n",
    "\n",
    "weights0 = [1.0, 0.0]\n",
    "weights1 = [0.67, 0.33]\n",
    "weights2 = [0.5, 0.5]\n",
    "weights3 = [0.33, 0.67]\n",
    "weights4 = [0.0, 1.0]\n",
    "\n",
    "weights={}\n",
    "weights[0]=weights0\n",
    "weights[1]=weights1\n",
    "weights[2]=weights2\n",
    "weights[3]=weights3\n",
    "weights[4]=weights4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Currently getting predictions with weighted average ( rgb = 1.0 , flow = 0.0  )\n",
      "\tAccuracy is 56.490 %\n",
      "\tTop-5 Accuracy is 79.672 %\n",
      "\n",
      "\n",
      "Currently getting predictions with weighted average ( rgb = 0.67 , flow = 0.33  )\n",
      "\tAccuracy is 66.323 %\n",
      "\tTop-5 Accuracy is 92.598 %\n",
      "\n",
      "\n",
      "Currently getting predictions with weighted average ( rgb = 0.5 , flow = 0.5  )\n",
      "\tAccuracy is 74.623 %\n",
      "\tTop-5 Accuracy is 93.233 %\n",
      "\n",
      "\n",
      "Currently getting predictions with weighted average ( rgb = 0.67 , flow = 0.33  )\n",
      "\tAccuracy is 77.372 %\n",
      "\tTop-5 Accuracy is 93.312 %\n",
      "\n",
      "\n",
      "Currently getting predictions with weighted average ( rgb = 0.0 , flow = 1.0  )\n",
      "\tAccuracy is 73.962 %\n",
      "\tTop-5 Accuracy is 91.885 %\n"
     ]
    }
   ],
   "source": [
    "# LSTM_RGB + LSTM_FLOW_512\n",
    "model_flow = LSTMCaffeDonahueFunctional(seq_input=seq_input,num_labels=num_labels)\n",
    "model_flow.load_weights(flow_paths[0])\n",
    "get_predictions_combo(model, model_flow, num_labels, classes_dictionary,  weights, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Currently getting predictions with weighted average ( rgb = 1.0 , flow = 0.0  )\n",
      "\tAccuracy is 56.490 %\n",
      "\tTop-5 Accuracy is 79.672 %\n",
      "\n",
      "\n",
      "Currently getting predictions with weighted average ( rgb = 0.67 , flow = 0.33  )\n",
      "\tAccuracy is 66.852 %\n",
      "\tTop-5 Accuracy is 91.673 %\n",
      "\n",
      "\n",
      "Currently getting predictions with weighted average ( rgb = 0.5 , flow = 0.5  )\n",
      "\tAccuracy is 74.280 %\n",
      "\tTop-5 Accuracy is 92.070 %\n",
      "\n",
      "\n",
      "Currently getting predictions with weighted average ( rgb = 0.67 , flow = 0.33  )\n",
      "\tAccuracy is 76.897 %\n",
      "\tTop-5 Accuracy is 91.938 %\n",
      "\n",
      "\n",
      "Currently getting predictions with weighted average ( rgb = 0.0 , flow = 1.0  )\n",
      "\tAccuracy is 73.619 %\n",
      "\tTop-5 Accuracy is 90.114 %\n"
     ]
    }
   ],
   "source": [
    "# LSTM_RGB + LSTM_FLOW_1024\n",
    "model_flow = LSTMCaffeDonahueFunctional(seq_input=seq_input,num_labels=num_labels,check1024=True)\n",
    "model_flow.load_weights(flow_paths[1])\n",
    "get_predictions_combo(model, model_flow, num_labels, classes_dictionary,  weights, 1)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
