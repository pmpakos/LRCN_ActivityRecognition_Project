{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #turn off gpu support, no need for it\n",
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from custom_models import *\n",
    "from inception_utils import *\n",
    "from image_processing import *\n",
    "from video_processing import *\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, model_flow, num_labels, classes_dictionary,  w, fnb):    \n",
    "    start = time.time()\n",
    "\n",
    "    root_path1 = 'full_videos_dataset/frames/'\n",
    "    root_path2 = 'full_videos_dataset/flow_images/'\n",
    "\n",
    "    print('\\n\\nCurrently getting predictions with weighted average ( rgb =',w[0],', flow =',w[1],' )')\n",
    "\n",
    "    conf_mat = np.zeros((num_labels,num_labels))\n",
    "    top5_correct = 0\n",
    "    vids_per_class = np.zeros(num_labels) #keep it for later stats extraction\n",
    "\n",
    "    pred_out = open('results/single_frame_results/combo'+str(fnb)+'/single_frame_predictions_'+str(w[0])+'_'+str(w[1])+'.txt','w')\n",
    "\n",
    "    cntr,N=0,3783\n",
    "    for line in open('data_a/ucf101_split1_testVideos.txt','r'):       \n",
    "        videoname1 = root_path1 + line.split()[0].split('/')[1]\n",
    "        videoname2 = root_path2 + line.split()[0].split('/')[1]\n",
    "        label = int(line.split()[1])\n",
    "\n",
    "        vids_per_class[label] +=1\n",
    "\n",
    "        #get mean of every column (101 of them) to find later greatest value among 101 and get predicted class\n",
    "        if(w[0]==0.0):\n",
    "            rgb_pred = np.zeros((101))\n",
    "            video2 = read_video(videoname2,'flow_images')\n",
    "            flow_pred = np.mean(model_flow.predict(video2),axis=0)\n",
    "            del video2\n",
    "        elif(w[1]==0.0):\n",
    "            video1 = read_video(videoname1,'frames')\n",
    "            rgb_pred = np.mean(model.predict(video1),axis=0)\n",
    "            flow_pred = np.zeros((101))\n",
    "            del video1\n",
    "        else:\n",
    "            video1 = read_video(videoname1,'frames')\n",
    "            rgb_pred = np.mean(model.predict(video1),axis=0)\n",
    "            video2 = read_video(videoname2,'flow_images')\n",
    "            flow_pred = np.mean(model_flow.predict(video2),axis=0)\n",
    "            del video1,video2\n",
    "\n",
    "        weighted_pred = w[0]*rgb_pred + w[1]*flow_pred\n",
    "\n",
    "        conf_mat[weighted_pred.argmax(),label] += 1  \n",
    "\n",
    "        pred_out.write('{:30} was classified as : {:25}'.format(line.split()[0].split('/')[1],classes_dictionary[weighted_pred.argmax()]))#,'with max_pred={:.4f}'.format(weighted_pred.max()))\n",
    "        pred_out.write('\\n\\nTop 5 predictions\\n-----------------\\n')\n",
    "\n",
    "        ind = np.argpartition(weighted_pred, -5)[-5:]\n",
    "        for i,cnt in zip(reversed(ind[np.argsort(weighted_pred[ind])]),range(5)):\n",
    "            pred_out.write(str(cnt+1)+' '+classes_dictionary[i]+'\\n')#, weighted_pred[i])\n",
    "            if(i==label):\n",
    "                top5_correct += 1\n",
    "        pred_out.write('\\n'+'-'*73+'\\n')\n",
    "\n",
    "        cntr+=1\n",
    "        print('{:.2f}'.format(cntr/N*100), end='',flush=True)\n",
    "        print('\\r', end='')\n",
    "        del rgb_pred,flow_pred,weighted_pred\n",
    "    pred_out.close()\n",
    "\n",
    "    #######################\n",
    "    accuracy = np.trace(conf_mat) / np.sum(conf_mat)\n",
    "    print('Accuracy is {:.3f}'.format(accuracy*100),'%')\n",
    "\n",
    "    top5_accuracy = top5_correct / np.sum(conf_mat)\n",
    "    print('Top-5 Accuracy is {:.3f}'.format(top5_accuracy*100),'%')\n",
    "\n",
    "    #######################\n",
    "    df_cm = pd.DataFrame(conf_mat, index = [classes_dictionary[i] for i in ([i for i in range(num_labels)])],\n",
    "                                 columns = [classes_dictionary[i] for i in ([i for i in range(num_labels)])])\n",
    "    sn.set(rc={'figure.figsize':(60,60)})\n",
    "    sn.heatmap(df_cm, annot=True).figure.savefig('results/single_frame_results/combo'+str(fnb)+'/single_frame_conf_mat_'+str(w[0])+'_'+str(w[1])+'.png', dpi=400)\n",
    "    plt.close() \n",
    "\n",
    "    #######################\n",
    "    stats_out = open('results/single_frame_results/combo'+str(fnb)+'/single_frame_stats_'+str(w[0])+'_'+str(w[1])+'.txt','w')    \n",
    "    for i in range(num_labels):\n",
    "        stats_out.write('Classified correctly '+str(int(conf_mat[i,i]))+' of '+str(int(vids_per_class[i]))+' for class '+classes_dictionary[i]+'\\n')\n",
    "    stats_out.close()\n",
    "\n",
    "    print('Partial execution time {:.2f}'.format(time.time()-start))\n",
    "    return conf_mat, accuracy, top5_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_combo(input_shape, num_labels, weights, rgb_p, flow_p, fnb):\n",
    "    start = time.time()\n",
    "\n",
    "    if('inception' in rgb_p):\n",
    "        model = get_model(weights='imagenet',input_shape=input_shape,num_labels=num_labels)\n",
    "    else:\n",
    "        model = CaffeDonahueFunctional(input_shape=input_shape,num_labels=num_labels)\n",
    "\n",
    "    model.load_weights(rgb_p)\n",
    "\n",
    "    model_flow = CaffeDonahueFunctional(input_shape=input_shape,num_labels=num_labels)\n",
    "    model_flow.load_weights(flow_p)\n",
    "    \n",
    "    conf_mat={}\n",
    "    acc={}\n",
    "    top5acc={}\n",
    "    \n",
    "    conf_mat[0], acc[0], top5acc[0] = get_predictions(model, model_flow, num_labels, classes_dictionary,  weights[0], fnb)\n",
    "    \n",
    "    conf_mat[1], acc[1], top5acc[1] = get_predictions(model, model_flow, num_labels, classes_dictionary,  weights[1], fnb)\n",
    "    \n",
    "    conf_mat[2], acc[2], top5acc[2] = get_predictions(model, model_flow, num_labels, classes_dictionary,  weights[2], fnb)\n",
    "    \n",
    "    conf_mat[3], acc[3], top5acc[3] = get_predictions(model, model_flow, num_labels, classes_dictionary,  weights[3], fnb)\n",
    "    \n",
    "    conf_mat[4], acc[4], top5acc[4] = get_predictions(model, model_flow, num_labels, classes_dictionary,  weights[4], fnb)\n",
    "    \n",
    "    print('Execution time {:.2f}'.format(time.time()-start))\n",
    "    return conf_mat, acc, top5acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "input_shape = (crop_height, crop_width, 3)\n",
    "\n",
    "classes_dictionary = pickle.load(open('data_a/action_dictionary.p','rb'))\n",
    "\n",
    "rgb_path = ['saved_models/caffenet_single_rgb.hdf5','saved_models/inception_rgb.hdf5']\n",
    "flow_path = ['saved_models/caffenet_single_flow.hdf5','saved_models/caffenet_single_flow_extra.h5']\n",
    "\n",
    "\n",
    "weights0 = [1.0, 0.0]\n",
    "weights1 = [0.67, 0.33]\n",
    "weights2 = [0.5, 0.5]\n",
    "weights3 = [0.33, 0.67]\n",
    "weights4 = [0.0, 1.0]\n",
    "\n",
    "weights={}\n",
    "weights[0]=weights0\n",
    "weights[1]=weights1\n",
    "weights[2]=weights2\n",
    "weights[3]=weights3\n",
    "weights[4]=weights4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Currently getting predictions with weighted average ( rgb = 1.0 , flow = 0.0  )\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "read_video() missing 1 required positional argument: 'data_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a9085d9b98cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# CaffenetRGB + CaffenetFLOW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mconf_mat0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop5acc0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_predictions_combo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrgb_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflow_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-4d9d726b6554>\u001b[0m in \u001b[0;36mget_predictions_combo\u001b[0;34m(input_shape, num_labels, weights, rgb_p, flow_p, fnb)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtop5acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mconf_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop5acc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_flow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses_dictionary\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfnb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mconf_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop5acc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_flow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses_dictionary\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfnb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-2c9689bbd65d>\u001b[0m in \u001b[0;36mget_predictions\u001b[0;34m(model, model_flow, num_labels, classes_dictionary, w, fnb)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mvideo2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32melif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mvideo1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideoname1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mrgb_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mflow_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m101\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: read_video() missing 1 required positional argument: 'data_type'"
     ]
    }
   ],
   "source": [
    "# CaffenetRGB + CaffenetFLOW\n",
    "conf_mat0, acc0, top5acc0 = get_predictions_combo(input_shape, num_labels, weights, rgb_path[0], flow_path[0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CaffenetRGB + FinetunedCaffenetFLOW\n",
    "conf_mat1, acc1, top5acc1 = get_predictions_combo(input_shape, num_labels, weights, rgb_path[0], flow_path[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# InceptionRGB + CaffenetFLOW\n",
    "conf_mat2, acc2, top5acc2 = get_predictions_combo(input_shape, num_labels, weights, rgb_path[1], flow_path[0], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# InceptionRGB + FinetunedCaffenetFLOW\n",
    "conf_mat3, acc3, top5acc3 = get_predictions_combo(input_shape, num_labels, weights, rgb_path[1], flow_path[1], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total Execution time {:.2f}'.format(time.time()-start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
